{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "import re\n",
    "import string\n",
    "from string import digits\n",
    "\n",
    "import unidecode\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import FrenchStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "data = pd.read_csv('../data/export_articles_EGC_2004_2018.csv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_abstract_title = pd.DataFrame(columns=['authors', 'title_abstract'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_abstract_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in data.iterrows():\n",
    "    if str(row['abstract']) == \"nan\":\n",
    "        data_abstract_title = data_abstract_title.append({'authors': row['authors'], 'title_abstract': row['title']}, ignore_index=True)\n",
    "    else:\n",
    "        data_abstract_title = data_abstract_title.append({'authors': row['authors'], 'title_abstract': row['title'] + \" \"+ row['abstract']}, ignore_index=True)\n",
    "    \n",
    "    #data_abstract_title = data_abstract_title.append({'num_doc': i, 'title_abstract': row['title'] + row['abstract']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "data_abstract_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buid array with all authors names uniq\n",
    "uniq_names = []\n",
    "setUniq=set(uniq_names)\n",
    "i = 0\n",
    "for row in data_abstract_title.iterrows():\n",
    "    athors_paper = data_abstract_title[\"authors\"].iloc[i].split(', ')\n",
    "    setAuthor=set(athors_paper)\n",
    "    uniq_names = uniq_names + list(setAuthor-setUniq)\n",
    "    setUniq=set(uniq_names)\n",
    "    i=i+1\n",
    "   \n",
    "\n",
    "# Get number of authors\n",
    "nb_authors = len(uniq_names)\n",
    "\n",
    "nb_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_abstract_title_uniq = pd.DataFrame(columns=['author', 'title_abstract'])   \n",
    "\n",
    "for name in uniq_names:\n",
    "    data_abstract_title_uniq = data_abstract_title_uniq.append({'author': name, 'title_abstract': \"\"}, ignore_index=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_abstract_title_uniq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, rowi in data_abstract_title.iterrows():\n",
    "    print(round((i*100)/len(data_abstract_title), 2),\"% / 100%\", end='\\r') # Print a loading bar ... \n",
    "    athors_paper = data_abstract_title[\"authors\"].iloc[i].split(', ')\n",
    "    paper=data_abstract_title[\"title_abstract\"].iloc[i]\n",
    "    for author in athors_paper:\n",
    "        data_abstract_title_uniq.loc[data_abstract_title_uniq[\"author\"]==author,[\"title_abstract\"]] = data_abstract_title_uniq.loc[data_abstract_title_uniq[\"author\"]==author,[\"title_abstract\"]]+ \" \" +paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_abstract_title_uniq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_abstract_title_uniq.iloc[3][\"title_abstract\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in data_abstract_title_uniq.iterrows():\n",
    "    # All char to lower case ...\n",
    "    row[\"title_abstract\"] = row[\"title_abstract\"].lower() \n",
    "    \n",
    "    # Remove all digits\n",
    "    remove_digits = str.maketrans('', '', digits)\n",
    "    row[\"title_abstract\"] = row[\"title_abstract\"].translate(remove_digits)\n",
    "    \n",
    "data_abstract_title_uniq1 = data_abstract_title_uniq\n",
    "data_abstract_title_uniq2 = data_abstract_title_uniq\n",
    "data_abstract_title_uniq3 = data_abstract_title_uniq\n",
    "data_abstract_title_uniq4 = data_abstract_title_uniq\n",
    "data_abstract_title_uniq5 = data_abstract_title_uniq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_abstract_title_uniq.iloc[3][\"title_abstract\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in data_abstract_title_uniq.iterrows():\n",
    "    translator = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    row[\"title_abstract\"] = translator.sub(' ', row[\"title_abstract\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_abstract_title_uniq.iloc[3][\"title_abstract\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in data_abstract_title_uniq.iterrows():\n",
    "    row[\"title_abstract\"] = ' '.join(row[\"title_abstract\"].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_abstract_title_uniq.iloc[3][\"title_abstract\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all accents\n",
    "#for index, row in data_abstract_title_uniq.iterrows():\n",
    "    #row[\"title_abstract\"] = unidecode.unidecode(row[\"title_abstract\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_abstract_title_uniq.iloc[3][\"title_abstract\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On retire les stop words de la langue francaise et anglaise\n",
    "stop_words = set(stopwords.words('perso'))\n",
    "stop_words.add('a')\n",
    "for index, row in data_abstract_title_uniq.iterrows():\n",
    "    tokens = word_tokenize(row[\"title_abstract\"])\n",
    "    result = [i for i in tokens if not i in stop_words]\n",
    "    row[\"title_abstract\"] = ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_abstract_title_uniq.iloc[3][\"title_abstract\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer= FrenchStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in data_abstract_title_uniq.iterrows():\n",
    "    tokens = word_tokenize(row[\"title_abstract\"])\n",
    "    stemmed=[]\n",
    "    for word in tokens:\n",
    "        stemmed.append(stemmer.stem(word))\n",
    "    row[\"title_abstract\"] = ' '.join(stemmed)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_abstract_title_uniq.iloc[3][\"title_abstract\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer.stem(stemmer.stem(\"dedi√©e\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
